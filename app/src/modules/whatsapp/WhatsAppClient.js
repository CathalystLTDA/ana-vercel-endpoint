// WhatsAppClient.js
const { Client, LocalAuth, MessageMedia } = require('whatsapp-web.js')
const fs = require('fs')
const qrcode = require('qrcode-terminal')
const { ADMIN_COMMANDS } = require('../../config')
const { saveConversationState, saveBotResponse } = require('../../utils/ConversationStateManager')
const {
	convertAudioToMp3,
	transcribeAudioWithWhisper,
	checkAudioDuration,
	findAddress,
	checkRunStatusAndWait,
	isValidMessageType,
	generateMariaVoiceMessage,
	probeInputFile,
} = require('../../utils')
const OpenAIModule = require('../openai')
require('dotenv').config()

let userTimers = {}

class WhatsAppClient {
	constructor() {
		this.client = null
	}

	init() {
		try {
			this.client = new Client({
				authStrategy: new LocalAuth(),
				puppeteer: {
					args: ['--no-sandbox', '--disable-setuid-sandbox'],
				},
			})

			this.client.on('qr', (qr) => {
				console.log('QR CODE GENERATED:')
				qrcode.generate(qr, { small: true })
			})

			this.client.on('remote_session_saved', () => {
				console.log('Sess√£o do WhatsApp salva no banco de dados remoto')
			})

			this.client.on('ready', () => {
				console.log('WhatsAppClient is ready!')
			})

			this.client.on('message', async (msg) => {
				const chatId = msg.from
				const messageType = msg.type
				const threadId = await OpenAIModule.ensureThreadId(chatId)

				// Clear any pending feedback timer for this chat.
				if (userTimers[chatId]) {
					clearTimeout(userTimers[chatId])
					delete userTimers[chatId]
				}

				console.log(`New message from: ${chatId}. Message Content: ${msg.body}`)
				const chat = await msg.getChat()
				chat.sendStateTyping()

				// If a run is still processing, ask the user to wait.
				if (await checkRunStatusAndWait(threadId)) {
					msg.reply(
						'* üö´ Percebi que voc√™ mandou outra mensagem, mas eu ainda estava processando a anterior. Como estou em fase de testes, pe√ßo para que mande apenas mensagens individuais e aguarde minha resposta antes de mandar outra mensagem (Essa mensagem ser√° desconsiderada).*'
					)
					return
				}

				// Ignore system messages.
				if (messageType === 'e2e_notification' || messageType === 'notification_template') {
					console.log('WhatsApp System message')
					return
				}

				// Validate supported message types.
				if (!isValidMessageType(messageType)) {
					console.log('Tipo de mensagem n√£o suportado:', messageType)
					msg.reply('Desculpe, no momento s√≥ posso responder a mensagens de texto e √°udio.')
					return
				}

				// Dispatch based on message type.
				try {
					switch (messageType) {
						case 'ptt':
							await this.handleVoiceMessage(msg, chatId, threadId, messageType)
							break
						case 'location':
							await this.handleLocationMessage(msg, chatId, threadId, messageType)
							break
						default:
							await this.handleTextMessage(msg, chatId, threadId, messageType)
					}
				} catch (error) {
					console.error('Error processing message:', error)
					msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
				}
			})

			return this.client.initialize()
		} catch (error) {
			console.error('Error during initialization', error)
			throw error
		}
	}

	/**
	 * Schedules a delayed feedback message.
	 */
	scheduleFeedback(chatId, msg) {
		userTimers[chatId] = setTimeout(() => {
			msg.reply(
				'Espero que eu tenha te ajudado! Se tiver um momento, adoraria receber seu feedback sobre a sua experi√™ncia comigo, √© muito importante para que eu possa entender melhor como ajudar a todos! Voc√™ pode deixar seu feedback aqui: https://maria-sigma.vercel.app/feedback. Obrigado por usar a MARIA e esperamos conversar com voc√™ novamente!'
			)
			delete userTimers[chatId]
		}, 600000) // 10 minutes
	}

	async handleVoiceMessage(msg, chatId, threadId, messageType) {
		console.log('Received audio message:', msg)
		try {
			const audioMedia = await msg.downloadMedia()
			console.log('Downloaded audio media:', audioMedia)

			const audioBuffer = Buffer.from(audioMedia.data, 'base64')
			const baseName = chatId.slice(0, 12)
			const audioPath = `./${baseName}-tempAudio.ogg`
			const convertedAudioPath = `./${baseName}-convertedAudio.mp3`
			const generatedMariaAudioMessage = `./${baseName}-generatedMariaAudio.mp3`

			fs.writeFileSync(audioPath, audioBuffer)
			probeInputFile(audioPath)
			console.log('Original audio file written to:', audioPath)

			await convertAudioToMp3(audioPath, convertedAudioPath)
			console.log('Converted audio file is ready:', convertedAudioPath)

			const audioDuration = await checkAudioDuration(convertedAudioPath)
			if (audioDuration >= 20) {
				fs.unlinkSync(convertedAudioPath)
				msg.reply(
					'Desculpa, mas por enquanto eu ainda n√£o posso ouvir √°udios com 20 segundos ou mais. Vamos tentar de novo?'
				)
				return
			}

			const transcription = await transcribeAudioWithWhisper(convertedAudioPath)
			const { assistantMessageId, runId } = await OpenAIModule.handleAddVoiceMessageToThread(threadId, transcription)
			const userMessage = transcription
			const userMessageId = await saveConversationState(chatId, userMessage, messageType, threadId)

			try {
				const assistantResponse = await OpenAIModule.getAssistantResponse(threadId, runId, assistantMessageId)
				const audioMessage = await generateMariaVoiceMessage(generatedMariaAudioMessage, assistantResponse)
				msg.reply(assistantResponse)
				if (audioMessage) {
					msg.reply(MessageMedia.fromFilePath(generatedMariaAudioMessage))
					fs.unlinkSync(generatedMariaAudioMessage)
				}
				await saveBotResponse(userMessageId, chatId, assistantResponse, threadId, OpenAIModule.assistantId)
				this.scheduleFeedback(chatId, msg)
			} catch (error) {
				console.error('Erro ao receber mensagem do Assistant:', error)
				msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
			}
		} catch (error) {
			console.error('Error processing voice message:', error)
			msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem de √°udio. Tente novamente.')
		}
	}

	async handleLocationMessage(msg, chatId, threadId, messageType) {
		let address = null
		try {
			address = await findAddress(msg.location.latitude, msg.location.longitude)
		} catch (error) {
			console.error('Error finding address:', error)
		}
		const userMessage = address
		try {
			const { assistantMessageId, runId } = await OpenAIModule.handleAddLocationMessageToThread(threadId, userMessage)
			const userMessageId = await saveConversationState(chatId, userMessage, messageType, threadId)
			try {
				const assistantResponse = await OpenAIModule.getAssistantResponse(threadId, runId, assistantMessageId)
				msg.reply(assistantResponse)
				await saveBotResponse(userMessageId, chatId, assistantResponse, threadId, OpenAIModule.assistantId)
				this.scheduleFeedback(chatId, msg)
			} catch (error) {
				console.error('Erro ao receber mensagem do Assistant:', error)
				msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
			}
		} catch (error) {
			console.error('Error processing location message:', error)
			msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
		}
	}

	async handleTextMessage(msg, chatId, threadId, messageType) {
		const userMessage = msg.body
		try {
			const { assistantMessageId, runId } = await OpenAIModule.handleAddMessageToThread(threadId, msg)
			const userMessageId = await saveConversationState(chatId, userMessage, messageType, threadId)
			try {
				const assistantResponse = await OpenAIModule.getAssistantResponse(threadId, runId, assistantMessageId)
				msg.reply(assistantResponse)
				await saveBotResponse(userMessageId, chatId, assistantResponse, threadId, OpenAIModule.assistantId)
				this.scheduleFeedback(chatId, msg)
			} catch (error) {
				console.error('Erro ao receber mensagem do Assistant:', error)
				msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
			}
		} catch (error) {
			console.error('Error processing text message:', error)
			msg.reply('Desculpe, ocorreu um erro ao processar sua mensagem.')
		}
	}
}

module.exports = new WhatsAppClient()
